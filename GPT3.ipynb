{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPT3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOJkyKZFsw+TmwfC20ui0U+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gimkuku/GPT3-colab/blob/main/GPT3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKKa2ZMeCFp1",
        "outputId": "5deaae46-a500-46c9-eb99-20308a4975f0"
      },
      "source": [
        "!pip install openai"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.6/dist-packages (0.2.4)\n",
            "Requirement already satisfied: requests>=2.20; python_version >= \"3.0\" in /usr/local/lib/python3.6/dist-packages (from openai) (2.24.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20; python_version >= \"3.0\"->openai) (1.25.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20; python_version >= \"3.0\"->openai) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20; python_version >= \"3.0\"->openai) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20; python_version >= \"3.0\"->openai) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJ0zo2j-CH7k"
      },
      "source": [
        "import json\r\n",
        "import openai"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LsGdISjCH-U"
      },
      "source": [
        "openai.api_key = \"sk-KWKlUMAaKpOhNvURPkHFXRiFzgpz9h2MVauInzVN\"\r\n",
        "response = openai.Completion.create(engine=\"davinci\", prompt=\"This is a test\", max_tokens=5)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Sitf8mRCICf",
        "outputId": "1153a60c-77c0-4464-dc66-293da4a993e8"
      },
      "source": [
        "!git clone https://github.com/shreyashankar/gpt3-sandbox.git"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'gpt3-sandbox'...\n",
            "remote: Enumerating objects: 36, done.\u001b[K\n",
            "remote: Counting objects: 100% (36/36), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 2389 (delta 16), reused 8 (delta 3), pack-reused 2353\u001b[K\n",
            "Receiving objects: 100% (2389/2389), 5.45 MiB | 14.83 MiB/s, done.\n",
            "Resolving deltas: 100% (649/649), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOZhLtd4CII-",
        "outputId": "658304c6-76c6-4b32-bcc2-2a50787abdb1"
      },
      "source": [
        "cd gpt3-sandbox"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gpt3-sandbox/gpt3-sandbox\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEcjFHtGDK0Q",
        "outputId": "cec48ca8-be83-4237-83da-9b15b89d6c38"
      },
      "source": [
        "!pip install -r api/requirements.txt"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: astroid==2.4.2 in /usr/local/lib/python3.6/dist-packages (from -r api/requirements.txt (line 1)) (2.4.2)\n",
            "Requirement already satisfied: certifi==2020.6.20 in /usr/local/lib/python3.6/dist-packages (from -r api/requirements.txt (line 2)) (2020.6.20)\n",
            "Requirement already satisfied: chardet==3.0.4 in /usr/local/lib/python3.6/dist-packages (from -r api/requirements.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: click==7.1.2 in /usr/local/lib/python3.6/dist-packages (from -r api/requirements.txt (line 4)) (7.1.2)\n",
            "Requirement already satisfied: Flask==1.1.2 in /usr/local/lib/python3.6/dist-packages (from -r api/requirements.txt (line 5)) (1.1.2)\n",
            "Requirement already satisfied: idna==2.10 in /usr/local/lib/python3.6/dist-packages (from -r api/requirements.txt (line 6)) (2.10)\n",
            "Requirement already satisfied: itsdangerous==1.1.0 in /usr/local/lib/python3.6/dist-packages (from -r api/requirements.txt (line 7)) (1.1.0)\n",
            "Requirement already satisfied: Jinja2==2.11.2 in /usr/local/lib/python3.6/dist-packages (from -r api/requirements.txt (line 8)) (2.11.2)\n",
            "Requirement already satisfied: MarkupSafe==1.1.1 in /usr/local/lib/python3.6/dist-packages (from -r api/requirements.txt (line 9)) (1.1.1)\n",
            "Requirement already satisfied: openai==0.2.4 in /usr/local/lib/python3.6/dist-packages (from -r api/requirements.txt (line 10)) (0.2.4)\n",
            "Requirement already satisfied: pylint==2.5.3 in /usr/local/lib/python3.6/dist-packages (from -r api/requirements.txt (line 11)) (2.5.3)\n",
            "Requirement already satisfied: python-dotenv==0.14.0 in /usr/local/lib/python3.6/dist-packages (from -r api/requirements.txt (line 12)) (0.14.0)\n",
            "Requirement already satisfied: requests==2.24.0 in /usr/local/lib/python3.6/dist-packages (from -r api/requirements.txt (line 13)) (2.24.0)\n",
            "Requirement already satisfied: six==1.15.0 in /usr/local/lib/python3.6/dist-packages (from -r api/requirements.txt (line 14)) (1.15.0)\n",
            "Requirement already satisfied: urllib3==1.25.9 in /usr/local/lib/python3.6/dist-packages (from -r api/requirements.txt (line 15)) (1.25.9)\n",
            "Requirement already satisfied: Werkzeug==1.0.1 in /usr/local/lib/python3.6/dist-packages (from -r api/requirements.txt (line 16)) (1.0.1)\n",
            "Requirement already satisfied: typed-ast<1.5,>=1.4.0; implementation_name == \"cpython\" and python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from astroid==2.4.2->-r api/requirements.txt (line 1)) (1.4.2)\n",
            "Requirement already satisfied: wrapt~=1.11 in /usr/local/lib/python3.6/dist-packages (from astroid==2.4.2->-r api/requirements.txt (line 1)) (1.12.1)\n",
            "Requirement already satisfied: lazy-object-proxy==1.4.* in /usr/local/lib/python3.6/dist-packages (from astroid==2.4.2->-r api/requirements.txt (line 1)) (1.4.3)\n",
            "Requirement already satisfied: isort<5,>=4.2.5 in /usr/local/lib/python3.6/dist-packages (from pylint==2.5.3->-r api/requirements.txt (line 11)) (4.3.21)\n",
            "Requirement already satisfied: toml>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from pylint==2.5.3->-r api/requirements.txt (line 11)) (0.10.2)\n",
            "Requirement already satisfied: mccabe<0.7,>=0.6 in /usr/local/lib/python3.6/dist-packages (from pylint==2.5.3->-r api/requirements.txt (line 11)) (0.6.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8LVbABRLpH1"
      },
      "source": [
        "gpt = GPT(engine=\"davinci\",\r\n",
        "          temperature=1,\r\n",
        "          max_tokens=100)\r\n",
        "gpt.add_example(Example('Birthday','Happy Birthday To You Happy Birthday To You Happy Birthday dear my child Happy Birthday To You'))\r\n",
        "gpt.add_example(Example('Looby loo','Here we go Looby loo, Here we go Looby Light, Here we go Looby loo, All on a Saturday night. You put your right hand in, You put your right hand out, You give your right hand a shake, shake, shake and turn yourself about. oh, '))\r\n",
        "gpt.add_example(Example('Little cabin','Little cabin in the wood, Little man by the window stood,Little Rabbit hopping by, Knocking at the door.\"Help me! Help me, sir!\" he said,\"fore the farmer bops my head\"\"Come on in\", the little man cried,\"Warm up by the fire“'))\r\n",
        "gpt.add_example(Example('Animal','Alligator, hedgehog, anteater, bear, rattlesnake, buffalo, anaconda, hareBullfrog, woodchuck, wolverine, goose, whipporwill, chipmunk, jackal. moose.Mud turtle, whale, bat, salamander, snail, maltese catBlack squirrel, coon, opossum, wren, red squirrel. loon, south guinea hen,Reindeer, blacksnake, ibex, nightingale, martin, wild drake, crocodile, and quailhouse rat, tosrat, white bear, doe, chickadee, peacock, and crowEagle, kingeron, sheep, duck, and widgeon, conger, armadillo, beaver, seal, pigeon.'))\r\n",
        "gpt.add_example(Example('little','I love little pussy her coat is so warm And if I dont hunt her shell do me no harmIll sit by the fire and give her some food And Pussy will love me because Im so good'))\r\n",
        "gpt.add_example(Example('POP! GOES THE WEASEL', 'All around the cobblers bench the monkey chased the weasel;The monkey thought was all in fun,Pop! Goes the weasel! A penny for a spool of thread A penny for a needle Thats the way the money goes  Pop! Goes the weasel!'))\r\n",
        "gpt.add_example(Example('OLD MACDONALD HAD A FARM', 'Old Macdonald had a farm E-I-E-I-O And on that farm he had some ducks E-I-E-I-O With a chick quack-quick here and a quick-quick there Here a chick there a chick everywhere a chick chick Old Macdonald had a farm E-I-E-I-O'))\r\n",
        "# gpt.add_example(Example('Two plus two equals four', '2 + 2 = 4'))\r\n",
        "# gpt.add_example(Example('The integral from zero to infinity', '\\\\int_0^{\\\\infty}'))\r\n",
        "# gpt.add_example(Example('The gradient of x squared plus two times x with respect to x', '\\\\nabla_x x^2   + 2x'))\r\n",
        "# gpt.add_example(Example('The log of two times x', '\\\\log{2x}'))\r\n",
        "# gpt.add_example(Example('x squared plus y squared plus equals z squared', 'x^2 + y^2 = z^2'))"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVtXoXGaMAxj"
      },
      "source": [
        "prompt = \"Display the lowest salary from the Worker table.\""
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNfha9TdMFbc"
      },
      "source": [
        "output = gpt.submit_request(prompt)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGPkQ6HRMYcs",
        "outputId": "5ff07afa-d958-4e8b-f3a9-2d6d5ddf69c3"
      },
      "source": [
        "\r\n",
        "output"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject text_completion id=cmpl-2K00uOLqfAVWbChrZmhqIH7IdPLd9 at 0x7faa709ce728> JSON: {\n",
              "  \"choices\": [\n",
              "    {\n",
              "      \"finish_reason\": \"stop\",\n",
              "      \"index\": 0,\n",
              "      \"logprobs\": null,\n",
              "      \"text\": \"output: Display the lowest salary from the Worker table.\\n\\n\"\n",
              "    }\n",
              "  ],\n",
              "  \"created\": 1611119288,\n",
              "  \"id\": \"cmpl-2K00uOLqfAVWbChrZmhqIH7IdPLd9\",\n",
              "  \"model\": \"davinci:2020-05-03\",\n",
              "  \"object\": \"text_completion\"\n",
              "}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCBKNmFJNLvA"
      },
      "source": [
        "prompt = \"2 더하기 2는\""
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "un5SEU8AOUnd"
      },
      "source": [
        "output = gpt.submit_request(prompt)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JJfd7buOV1Y",
        "outputId": "46242065-cc1c-4a97-c039-611f3f7b8111"
      },
      "source": [
        "output"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject text_completion id=cmpl-2K09E08ezYIoqL1vvDNj8P1a25eZ1 at 0x7faa70562570> JSON: {\n",
              "  \"choices\": [\n",
              "    {\n",
              "      \"finish_reason\": \"stop\",\n",
              "      \"index\": 0,\n",
              "      \"logprobs\": null,\n",
              "      \"text\": \"output: 2 + 2 = 4\\n\\n\"\n",
              "    }\n",
              "  ],\n",
              "  \"created\": 1611119804,\n",
              "  \"id\": \"cmpl-2K09E08ezYIoqL1vvDNj8P1a25eZ1\",\n",
              "  \"model\": \"davinci:2020-05-03\",\n",
              "  \"object\": \"text_completion\"\n",
              "}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8jzqk7TR9Vt"
      },
      "source": [
        "prompt = \"2 정재 4 는\""
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqbAAe9ZSBlW",
        "outputId": "3c0e2c3a-a716-4070-9d57-0b67c005d6a9"
      },
      "source": [
        "output = gpt.submit_request(prompt)\r\n",
        "output"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject text_completion id=cmpl-2K0PFQghl3N9U6UkvHBlnH9BHgDCK at 0x7faa705845c8> JSON: {\n",
              "  \"choices\": [\n",
              "    {\n",
              "      \"finish_reason\": \"stop\",\n",
              "      \"index\": 0,\n",
              "      \"logprobs\": null,\n",
              "      \"text\": \"output: 2 + 4 =\\n\\n\"\n",
              "    }\n",
              "  ],\n",
              "  \"created\": 1611120797,\n",
              "  \"id\": \"cmpl-2K0PFQghl3N9U6UkvHBlnH9BHgDCK\",\n",
              "  \"model\": \"davinci:2020-05-03\",\n",
              "  \"object\": \"text_completion\"\n",
              "}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcGAob74cX6o"
      },
      "source": [
        "prompt = \"puppy\""
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImatPouAccOD",
        "outputId": "f71d0c5a-102d-4fee-d95d-6d2412d3f50d"
      },
      "source": [
        "output = gpt.submit_request(prompt)\r\n",
        "output"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject text_completion id=cmpl-2K1NdGPxZQsji94JgRbaBNDp9tE95 at 0x7faa704d3258> JSON: {\n",
              "  \"choices\": [\n",
              "    {\n",
              "      \"finish_reason\": \"length\",\n",
              "      \"index\": 0,\n",
              "      \"logprobs\": null,\n",
              "      \"text\": \"output: How much is that puppy in the store window? \\\"It is not for sale.\\\" The little boy said, \\\"I MUST have that puppy, his coat is SOOO WOOF, SO WOOF, SO WOOF, AND I WANT THAT WOOF PUPPY IN THE STORE WINDOW. How much is that puppy in the store window? The little girl said, I must have that puppy, his LIFE is SOOO DARE,\"\n",
              "    }\n",
              "  ],\n",
              "  \"created\": 1611124541,\n",
              "  \"id\": \"cmpl-2K1NdGPxZQsji94JgRbaBNDp9tE95\",\n",
              "  \"model\": \"davinci:2020-05-03\",\n",
              "  \"object\": \"text_completion\"\n",
              "}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SP0z9CGchage",
        "outputId": "ef379611-62c9-4b74-efb7-a627fa709f2a"
      },
      "source": [
        "import os\r\n",
        "import sys\r\n",
        "from api import GPT, Example, UIConfig\r\n",
        "from api import demo_web_app\r\n",
        "\r\n",
        "\r\n",
        "# Construct GPT object and show some examples\r\n",
        "gpt = GPT(engine=\"davinci\",\r\n",
        "          temperature=0.5,\r\n",
        "          max_tokens=100)\r\n",
        "\r\n",
        "gpt.add_example(Example('Neural networks are like',\r\n",
        "                        'genetic algorithms in that both are systems that learn from experience.'))\r\n",
        "gpt.add_example(Example('Social media is like',\r\n",
        "                        'a market in that both are systems that coordinate the actions of many individuals.'))\r\n",
        "gpt.add_example(Example(\r\n",
        "    'A2E is like', 'lipofuscin in that both are byproducts of the normal operation of a system.'))\r\n",
        "gpt.add_example(Example('Haskell is like',\r\n",
        "                        'LISP in that both are functional languages.'))\r\n",
        "gpt.add_example(Example('Quaternions are like',\r\n",
        "                        'matrices in that both are used to represent rotations in three dimensions.'))\r\n",
        "gpt.add_example(Example('Quaternions are like',\r\n",
        "                        'octonions in that both are examples of non-commutative algebra.'))\r\n",
        "\r\n",
        "prompt = \"computer science is like\"\r\n",
        "output = gpt.submit_request(prompt)\r\n",
        "output\r\n"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject text_completion id=cmpl-2K1XgB3P5LHujYcJQIMebAkjHQqCu at 0x7faa704efeb8> JSON: {\n",
              "  \"choices\": [\n",
              "    {\n",
              "      \"finish_reason\": \"stop\",\n",
              "      \"index\": 0,\n",
              "      \"logprobs\": null,\n",
              "      \"text\": \"output: biology in that both are concerned with complex systems.\\n\\n\"\n",
              "    }\n",
              "  ],\n",
              "  \"created\": 1611125164,\n",
              "  \"id\": \"cmpl-2K1XgB3P5LHujYcJQIMebAkjHQqCu\",\n",
              "  \"model\": \"davinci:2020-05-03\",\n",
              "  \"object\": \"text_completion\"\n",
              "}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZStH4jijJIx",
        "outputId": "91df81bd-e0a7-4743-b3d5-9b54d75cd284"
      },
      "source": [
        "gpt = GPT(engine=\"davinci\",\r\n",
        "          temperature=0.4,\r\n",
        "          max_tokens=60)\r\n",
        "\r\n",
        "gpt.add_example(Example('Thank John for the book.',\r\n",
        "                        'Dear John, Thank you so much for the book. I really appreciate it. I hope to hang out soon. Your friend, Sarah.'))\r\n",
        "\r\n",
        "gpt.add_example(Example('Tell TechCorp I appreciate the great service.',\r\n",
        "                        'To Whom it May Concern, I want you to know that I appreciate the great service at TechCorp. The staff is outstanding and I enjoy every visit. Sincerely, Bill Johnson'))\r\n",
        "\r\n",
        "gpt.add_example(Example('Invoice Kelly Watkins $500 for design consultation.',\r\n",
        "                        'Dear Ms. Watkins, This is my invoice for $500 for design consultation. It was a pleasure to work with you. Sincerely, Emily Fields'))\r\n",
        "\r\n",
        "gpt.add_example(Example('Invite Amanda and Paul to the company event Friday night.',\r\n",
        "                        'Dear Amanda and Paul, I hope this finds you doing well. I want to invite you to our company event on Friday night. It will be a great opportunity for networking and there will be food and drinks. Should be fun. Best, Ryan'))\r\n",
        "\r\n",
        "prompt = \"Tell Yujin politely that please do not eat beef all\"\r\n",
        "output = gpt.submit_request(prompt)\r\n",
        "output"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject text_completion id=cmpl-2K1jzZZ8F8Bpx1oWFWS9EY4z0rdUy at 0x7faa70494410> JSON: {\n",
              "  \"choices\": [\n",
              "    {\n",
              "      \"finish_reason\": \"length\",\n",
              "      \"index\": 0,\n",
              "      \"logprobs\": null,\n",
              "      \"text\": \"day long.\\noutput: Dear Yujin, I am writing to ask you to please not eat beef all day long. I know you have a very strong taste for it, but it is not good for your health. Sincerely, Emily\\noutput: Ask Emily to pay $500 to Amanda\"\n",
              "    }\n",
              "  ],\n",
              "  \"created\": 1611125927,\n",
              "  \"id\": \"cmpl-2K1jzZZ8F8Bpx1oWFWS9EY4z0rdUy\",\n",
              "  \"model\": \"davinci:2020-05-03\",\n",
              "  \"object\": \"text_completion\"\n",
              "}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_YUSCw3ko5a",
        "outputId": "1db59e09-cd40-42ed-8b3a-0440ee24f339"
      },
      "source": [
        "\r\n",
        "gpt = GPT(temperature=0.5, max_tokens=500)\r\n",
        "\r\n",
        "gpt.add_example(Example(\r\n",
        "    \"how to roast eggplant\",\r\n",
        "    \"How do you cook eggplant in the oven? Well, there are a couple ways. To roast whole eggplants in the oven, leave the skin on and roast at 400 degrees F (200 degrees C) until the skin gets wrinkly and begins to collapse in on the softened fruit. This method will also produce velvety smooth eggplant dips or spreads.\"\r\n",
        "))\r\n",
        "\r\n",
        "gpt.add_example(Example(\r\n",
        "    \"how to bake eggplant\",\r\n",
        "    \"To bake eggplant, you'll cut the eggplant into rounds or strips and prepare them as the recipe indicates -- for example, you can dredge them in egg and breadcrumbs or simply brush them with olive oil and bake them in a 350 degree F oven.\"\r\n",
        "))\r\n",
        "\r\n",
        "gpt.add_example(Example(\r\n",
        "    \"how to make puerto rican steamed rice\",\r\n",
        "    \"Bring vegetable oil, water, and salt to a boil in a saucepan over high heat. Add rice, and cook until the water has just about cooked out; stir. Reduce heat to medium-low. Cover, and cook for 20 to 25 minutes. Stir again, and serve. Rice may be a little sticky and may stick to bottom of pot.\"\r\n",
        "))\r\n",
        "\r\n",
        "gpt.add_example(Example(\r\n",
        "    \"how to make oatmeal peanut butter cookies\",\r\n",
        "    \"Preheat oven to 350 degrees F (175 degrees C). In a large bowl, cream together shortening, margarine, brown sugar, white sugar, and peanut butter until smooth. Beat in the eggs one at a time until well blended. Combine the flour, baking soda, and salt; stir into the creamed mixture. Mix in the oats until just combined. Drop by teaspoonfuls onto ungreased cookie sheets. Bake for 10 to 15 minutes in the preheated oven, or until just light brown. Don't over-bake. Cool and store in an airtight container.\"\r\n",
        "))\r\n",
        "prompt = \"how to make kimchi\"\r\n",
        "output = gpt.submit_request(prompt)\r\n",
        "output"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject text_completion id=cmpl-2K1gtYcX1ciUpB57es1bK5rdeADpn at 0x7faa704efe08> JSON: {\n",
              "  \"choices\": [\n",
              "    {\n",
              "      \"finish_reason\": \"stop\",\n",
              "      \"index\": 0,\n",
              "      \"logprobs\": null,\n",
              "      \"text\": \"output: The kimchi has a very spicy taste and it is a little sour. The vegetable is usually shredded cabbage. The cabbage is salted and left out for a day. The cabbage is then washed and chopped into very small pieces. The chopped cabbage is then placed in a container and a dressing is added, usually made from fish sauce, garlic, red pepper, ginger and other spices. The kimchi is then left to ferment in a cool place for about one week.\\n\\n\"\n",
              "    }\n",
              "  ],\n",
              "  \"created\": 1611125735,\n",
              "  \"id\": \"cmpl-2K1gtYcX1ciUpB57es1bK5rdeADpn\",\n",
              "  \"model\": \"davinci:2020-05-03\",\n",
              "  \"object\": \"text_completion\"\n",
              "}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    }
  ]
}