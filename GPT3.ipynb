{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPT3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNBIuF+ZzNs6BotEu1VBc3x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gimkuku/GPT3-colab/blob/main/GPT3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKKa2ZMeCFp1",
        "outputId": "2d5109ee-bff3-473f-b44c-dccfa319dd31"
      },
      "source": [
        "!pip install openai"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.6/dist-packages (0.2.4)\n",
            "Requirement already satisfied: requests>=2.20; python_version >= \"3.0\" in /usr/local/lib/python3.6/dist-packages (from openai) (2.24.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20; python_version >= \"3.0\"->openai) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20; python_version >= \"3.0\"->openai) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20; python_version >= \"3.0\"->openai) (1.25.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20; python_version >= \"3.0\"->openai) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QRw2rcTh_7Y",
        "outputId": "ee58309a-37a2-4ae4-c278-5bf8afdc3d03"
      },
      "source": [
        "!sudo apt-get install -y fonts-nanum\r\n",
        "!sudo fc-cache -fv\r\n",
        "!rm ~/.cache/matplotlib -rf"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "fonts-nanum is already the newest version (20170925-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 13 not upgraded.\n",
            "/usr/share/fonts: caching, new cache contents: 0 fonts, 1 dirs\n",
            "/usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 3 dirs\n",
            "/usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/nanum: caching, new cache contents: 10 fonts, 0 dirs\n",
            "/usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\n",
            "/root/.local/share/fonts: skipping, no such directory\n",
            "/root/.fonts: skipping, no such directory\n",
            "/var/cache/fontconfig: cleaning cache directory\n",
            "/root/.cache/fontconfig: not cleaning non-existent cache directory\n",
            "/root/.fontconfig: not cleaning non-existent cache directory\n",
            "fc-cache: succeeded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMvIhur-iH8q"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "plt.rc('font', family='NanumBarunGothic')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJ0zo2j-CH7k"
      },
      "source": [
        "import json\r\n",
        "import openai"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LsGdISjCH-U"
      },
      "source": [
        "openai.api_key = \"sk-KWKlUMAaKpOhNvURPkHFXRiFzgpz9h2MVauInzVN\"\r\n",
        "response = openai.Completion.create(engine=\"davinci\", prompt=\"This is a test\", max_tokens=5)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Sitf8mRCICf",
        "outputId": "b83d9323-a267-47f2-c06a-d2420b0302cd"
      },
      "source": [
        "!git clone https://github.com/shreyashankar/gpt3-sandbox.git"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'gpt3-sandbox'...\n",
            "remote: Enumerating objects: 36, done.\u001b[K\n",
            "remote: Counting objects: 100% (36/36), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 2389 (delta 16), reused 8 (delta 3), pack-reused 2353\u001b[K\n",
            "Receiving objects: 100% (2389/2389), 5.45 MiB | 22.86 MiB/s, done.\n",
            "Resolving deltas: 100% (649/649), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOZhLtd4CII-",
        "outputId": "79f2bc4a-5563-414f-f3e3-9d9ddd89751e"
      },
      "source": [
        "cd gpt3-sandbox"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gpt3-sandbox\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEcjFHtGDK0Q",
        "outputId": "c323f955-de09-4cb9-862b-255869da3833"
      },
      "source": [
        "!pip install -r api/requirements.txt"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'api/requirements.txt'\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZStH4jijJIx",
        "outputId": "91df81bd-e0a7-4743-b3d5-9b54d75cd284"
      },
      "source": [
        "gpt = GPT(engine=\"davinci\",\r\n",
        "          temperature=0.4,\r\n",
        "          max_tokens=60)\r\n",
        "\r\n",
        "gpt.add_example(Example('Thank John for the book.',\r\n",
        "                        'Dear John, Thank you so much for the book. I really appreciate it. I hope to hang out soon. Your friend, Sarah.'))\r\n",
        "\r\n",
        "gpt.add_example(Example('Tell TechCorp I appreciate the great service.',\r\n",
        "                        'To Whom it May Concern, I want you to know that I appreciate the great service at TechCorp. The staff is outstanding and I enjoy every visit. Sincerely, Bill Johnson'))\r\n",
        "\r\n",
        "gpt.add_example(Example('Invoice Kelly Watkins $500 for design consultation.',\r\n",
        "                        'Dear Ms. Watkins, This is my invoice for $500 for design consultation. It was a pleasure to work with you. Sincerely, Emily Fields'))\r\n",
        "\r\n",
        "gpt.add_example(Example('Invite Amanda and Paul to the company event Friday night.',\r\n",
        "                        'Dear Amanda and Paul, I hope this finds you doing well. I want to invite you to our company event on Friday night. It will be a great opportunity for networking and there will be food and drinks. Should be fun. Best, Ryan'))\r\n",
        "\r\n",
        "prompt = \"Tell Yujin politely that please do not eat beef all\"\r\n",
        "output = gpt.submit_request(prompt)\r\n",
        "output"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject text_completion id=cmpl-2K1jzZZ8F8Bpx1oWFWS9EY4z0rdUy at 0x7faa70494410> JSON: {\n",
              "  \"choices\": [\n",
              "    {\n",
              "      \"finish_reason\": \"length\",\n",
              "      \"index\": 0,\n",
              "      \"logprobs\": null,\n",
              "      \"text\": \"day long.\\noutput: Dear Yujin, I am writing to ask you to please not eat beef all day long. I know you have a very strong taste for it, but it is not good for your health. Sincerely, Emily\\noutput: Ask Emily to pay $500 to Amanda\"\n",
              "    }\n",
              "  ],\n",
              "  \"created\": 1611125927,\n",
              "  \"id\": \"cmpl-2K1jzZZ8F8Bpx1oWFWS9EY4z0rdUy\",\n",
              "  \"model\": \"davinci:2020-05-03\",\n",
              "  \"object\": \"text_completion\"\n",
              "}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7Dh8_bLee0e",
        "outputId": "538bab01-93db-45c3-deb7-fae9ab2bbbf0"
      },
      "source": [
        "ls -l\r\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 508\n",
            "drwxr-xr-x 2 root root   4096 Jan 22 05:20 \u001b[0m\u001b[01;34mapi\u001b[0m/\n",
            "drwxr-xr-x 2 root root   4096 Jan 22 05:20 \u001b[01;34mdocs\u001b[0m/\n",
            "drwxr-xr-x 2 root root   4096 Jan 22 05:20 \u001b[01;34mexamples\u001b[0m/\n",
            "-rw-r--r-- 1 root root   1071 Jan 22 05:20 LICENSE\n",
            "-rw-r--r-- 1 root root   1021 Jan 22 05:20 package.json\n",
            "drwxr-xr-x 2 root root   4096 Jan 22 05:20 \u001b[01;34mpublic\u001b[0m/\n",
            "-rw-r--r-- 1 root root   6623 Jan 22 05:20 README.md\n",
            "drwxr-xr-x 2 root root   4096 Jan 22 05:20 \u001b[01;34msrc\u001b[0m/\n",
            "-rw-r--r-- 1 root root 481679 Jan 22 05:20 yarn.lock\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHjy-ADWe0-J",
        "outputId": "391be5c9-567a-4006-f13f-376301217704"
      },
      "source": [
        "cd gpt3-sandbox"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'gpt3-sandbox'\n",
            "/content/gpt3-sandbox/gpt3-sandbox\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_YUSCw3ko5a",
        "outputId": "09d7b9e3-8f0f-49b0-e751-938df6f7a08d"
      },
      "source": [
        "from api import GPT,Example\r\n",
        "gpt = GPT(temperature=0.8, max_tokens=1200)\r\n",
        "\r\n",
        "gpt.add_example(Example(\r\n",
        "    \"Olivia Rodrigo\",\r\n",
        "    \"I got my driver's license last week\\nJust like we always talked about\\n'Cause you were so excited for me\\n    To finally drive up to your house\\nBut today I drove through the suburbs\\nCrying 'cause you weren't around\"\r\n",
        "))\r\n",
        "\r\n",
        "gpt.add_example(Example(\r\n",
        "    \"Billie Eilish\",\r\n",
        "    \"Dime si me echas de meno' aún\\n\\\r\n",
        "    Dime si no me perdonas aún\\n\\\r\n",
        "    ¿Qué harás con to' este veneno? Na' bueno\\n\\\r\n",
        "    Dime si me echas de meno' aún\"))\r\n",
        "\r\n",
        "gpt.add_example(Example(\r\n",
        "    \"Ariana Grande\",\r\n",
        "    \"You might think I'm crazy\\n\\\r\n",
        "    The way I've been cravin'\\n\\\r\n",
        "    If I put it quite plainly\\n\\\r\n",
        "    Just gimme them babies\\n\\\r\n",
        "    So what you doin' tonight?\\n\\\r\n",
        "    Better say, Doin' you right (Yeah)\\n\\\r\n",
        "    Watchin' movies, but we ain't seen a thing tonight (Yeah)\"))\r\n",
        "\r\n",
        "gpt.add_example(Example(\r\n",
        "    \"Cadibi\",\r\n",
        "    \"Whores in this house\\n\\\r\n",
        "    There's some whores in this house\\n\\\r\n",
        "    There's some whores in this house\\n\\\r\n",
        "    There's some whores in this house (Hol' up)\\n\\\r\n",
        "    I said certified freak, seven days a week\\n\\\r\n",
        "    Wet-ass pussy, make that pullout game weak, woo (Ah)\"))\r\n",
        "gpt.add_example(Example(\r\n",
        "    \"BTS\",\r\n",
        "    \"어느 날 세상이 멈췄어\\n\\\r\n",
        "아무런 예고도 하나 없이\\n\\\r\n",
        "봄은 기다림을 몰라서\\n\\\r\n",
        "눈치 없이 와버렸어\\n\\\r\n",
        "발자국이 지워진 거리\\n\\\r\n",
        "여기 넘어져있는 나\\n\\\r\n",
        "혼자 가네 시간이\\n\\\r\n",
        "미안해 말도 없이 yeah\\n\\\r\n",
        "오늘도 비가 내릴 것 같아\\n\\\r\n",
        "흠뻑 젖어버렸네\\n\\\r\n",
        "아직도 멈추질 않아\\n\\\r\n",
        "저 먹구름보다 빨리 달려가\"))\r\n",
        "\r\n",
        "prompt = \"BTS\"\r\n",
        "output = gpt.submit_request(prompt)\r\n",
        "output"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject text_completion id=cmpl-2KjPkxGPUWOya7GjPW3wnFpSlAk0v at 0x7f42e15e5d58> JSON: {\n",
              "  \"choices\": [\n",
              "    {\n",
              "      \"finish_reason\": \"stop\",\n",
              "      \"index\": 0,\n",
              "      \"logprobs\": null,\n",
              "      \"text\": \"output: You don't know me\\nthat's what makes me lonely\\n\\n\"\n",
              "    }\n",
              "  ],\n",
              "  \"created\": 1611293808,\n",
              "  \"id\": \"cmpl-2KjPkxGPUWOya7GjPW3wnFpSlAk0v\",\n",
              "  \"model\": \"davinci:2020-05-03\",\n",
              "  \"object\": \"text_completion\"\n",
              "}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EALOO7Xqedxn",
        "outputId": "8b174ddd-9640-442e-90b2-ec3e08980cef"
      },
      "source": [
        "from api import GPT,Example\r\n",
        "gpt = GPT(temperature=0.8, max_tokens=200)\r\n",
        "\r\n",
        "gpt.add_example(Example(\r\n",
        "    \"한산섬 달 밝은 밤에\",\r\n",
        "    \"한산섬 달 밝은 밤에 수루에 혼자 앉아\\n\\\r\n",
        "큰 칼 옆에 차고 깊은 시름 하는 적에\"))\r\n",
        "#어디서 일성호가는 남의 애를 끊나니\\n\\\"))\r\n",
        "\r\n",
        "gpt.add_example(Example(\r\n",
        "    \"철령 높은 봉에\",\r\n",
        "    \"철령 높은 봉에 쉬어 넘는 저 구름아\\n\\\r\n",
        "고신원루를 비 삼아 뛰워다가\"))\r\n",
        "#임 계신 구중심처에 뿌려 본들 어떠리\"))\r\n",
        "\r\n",
        "gpt.add_example(Example(\r\n",
        "    \"세상 사람들이\",\r\n",
        "    \"세상 사람들이 입들만 성하여서\\n\\\r\n",
        "제 허물 전혀 잊고 남의 흉 보는 괴야\"))\r\n",
        "#남의 흉 보거라 말고 제 허물을 고치고저\"))\r\n",
        "\r\n",
        "gpt.add_example(Example(\r\n",
        "    \"심산에 밤이 드니\",\r\n",
        "    \"심산에 밤이 드니 북풍이 더욱 차다\\n\\\r\n",
        "옥루고처에도 이 바람 부는 게오\"))\r\n",
        "#긴밤에 치우신가 북두 비겨 바래로다\"))\r\n",
        "gpt.add_example(Example(\r\n",
        "    \"동창이 밝았느냐\",\r\n",
        "    \"동창이 밝았느냐 노고지리 우지진다\\n\\\r\n",
        "소치는 아이는 상기 아니 일었느냐\"))\r\n",
        "#재 너머 사래 긴 밭을 언제 갈려 하느니\"))\r\n",
        "\r\n",
        "gpt.add_example(Example(\r\n",
        "    \"오늘도 다 새거다 \",\r\n",
        "    \"오늘도 다 새거다 호미 메고 가자스라\\n\\\r\n",
        "내 논 다 매어든 네 논 좀 매어주마\"))\r\n",
        "#올 길에 뽕 따다가 누에 먹여 보자스라\"))\r\n",
        "\r\n",
        "gpt.add_example(Example(\r\n",
        "    \"이고 진 저 늙은이 짐 벗어 나를 주오\",\r\n",
        "    \"이고 진 저 늙은이 짐 벗어 나를 주오\\n\\\r\n",
        "나는 젊었거니 돌이라 무거울까\"))\r\n",
        "#늙기도 설워라커든 짐을 조차 지실까\"))\r\n",
        "\r\n",
        "gpt.add_example(Example(\r\n",
        "    \"지당에 비 뿌리고\",\r\n",
        "    \"지당에 비 뿌리고 양류에 내 끼인 제\\n\\\r\n",
        "사공은 어디 가고 빈 배만 매었는고\"))\r\n",
        "#석양에 짝 잃은 갈매기만 오락가락 하노라\"))\r\n",
        "\r\n",
        "#여기까지 학습시켜왔을때 결과\r\n",
        "#prompt = \"바람이 불어오니\"\r\n",
        "#\"\\ubc14\\ub78c\\uc774 \\ubd88\\uc5b4\\uc624\\ub2c8\\n\\uc9c4\\ub3d9\\ud560 \\ub54c\\uae30\\uc5d0 \\uac00\\uc744\\uc774 \\uc5b4\\ub528\\uc5b4\\n\\ud3c9\\uc9c0 \\ubc14\\ub77c\\ubcf4\\uba70 \\uc4ac\\ubc15 \\uc11c\\ub85c \\uc54c\\ub824\\uc624\\n\\n\"\r\n",
        "#\"바람이 불어오니\r\n",
        "#진동할 때기에 가을이 어딨어\r\n",
        "#평지 바라보며 쒬박 서로 알려오\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "gpt.add_example(Example(\r\n",
        "    \"꿈에 다니는 길이\",\r\n",
        "    \"꿈에 다니는 길이 자취곧 날 양이면\\n\\\r\n",
        "   님의 집 창 밖이 석로라도 닳으련마는\"))\r\n",
        "   #꿈길이 자취 없으니 그를 슬허하노라\"))\r\n",
        "\r\n",
        "gpt.add_example(Example(\r\n",
        "    \"님 그린 상사몽이\",\r\n",
        "    \"님 그린 상사몽이 실솔의 넋이 되어\\n\\\r\n",
        "   추야장 깊은 밤에 님의 방에 들었다가\"))\r\n",
        "   #날 잊고 깊이 든 잠을 깨워 볼까 하노라\"))\r\n",
        "\r\n",
        "gpt.add_example(Example(\r\n",
        "    \"님이 헤오시매\",\r\n",
        "    \" 님이 헤오시매 나는 전혀 믿었더니\\n\\\r\n",
        "   날 사랑하던 정을 뉘손대 옮기신고\"))\r\n",
        "   #처음에 믜시던 것이면 이대도록 설오랴\"))\r\n",
        "gpt.add_example(Example(\r\n",
        "    \"마음이 어린 후이니\",\r\n",
        "    \"마음이 어린 후이니 하는 일이 다 어리다\\n\\\r\n",
        "   만중 운산에 어느 님 오리마난\"))\r\n",
        "   #지는 잎 부는 바람에 행여 귄가 하노라\"))\r\n",
        "\r\n",
        "gpt.add_example(Example(\r\n",
        "    \"뫼는 높으나 높고\",\r\n",
        "    \" 뫼는 높으나 높고 물은 기나 길다\\n\\\r\n",
        "   높은 뫼 긴 물에 갈길도 그지없다\"))\r\n",
        "   #님 그려 젖은 소매는 어느 적에 마를꼬\"))\r\n",
        "\r\n",
        "gpt.add_example(Example(\r\n",
        "    \"청초 우거진 골에\",\r\n",
        "    \"청초 우거진 골에 자는다 누웠는다\\n\\\r\n",
        "   홍안은 어디 두고 백골만 묻혔는다\"))\r\n",
        "   #잔 잡아 권할 이 없으니 그를 슬허하노라\"))\r\n",
        "\r\n",
        "gpt.add_example(Example(\r\n",
        "    \"청춘에 곱던 양자\",\r\n",
        "    \"청춘에 곱던 양자 님으로야 다 늙거다\\n\\\r\n",
        "   이제 님이 보면 날인 줄 알으실까\"))\r\n",
        "   #아모나 내 형용 그려다가 님의손대 드리고저\"))\r\n",
        "\r\n",
        "gpt.add_example(Example(\r\n",
        "    \"임 그려 얻은 병을\",\r\n",
        "    \"임 그려 얻은 병을 약으로 고칠쏜가\\n\\\r\n",
        "   한숨이야 눈물이야 오매에 맺혔세라\"))\r\n",
        "   #일신이 죽지 못한 전은 못 잊을까 하노라\"))\r\n",
        "\r\n",
        "#바람이 불어오니\r\n",
        "#바람이 불어오니 내 손은 칠흑에 가 \r\n",
        "#비의 손님을 발치나 나는 그 비를 맞으리  \r\n",
        "#김천에 나라자와 나란 분명히 생각나\r\n",
        "prompt = \"사랑이 사랑인지라\"\r\n",
        "output = gpt.submit_request(prompt)\r\n",
        "output"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject text_completion id=cmpl-2KkThPGkYef5Ila2J27uNnRXAZcho at 0x7f42e15c0410> JSON: {\n",
              "  \"choices\": [\n",
              "    {\n",
              "      \"finish_reason\": \"stop\",\n",
              "      \"index\": 0,\n",
              "      \"logprobs\": null,\n",
              "      \"text\": \"output: \\uc0ac\\ub791\\uc774 \\uc0ac\\ub791\\uc778\\uc9c0\\ub77c \\uac00\\uc7a5 \\ub9ce\\uc740 \\uac83 \\uc0ac\\ub791\\uc778\\uc9c0\\ub77c \\n\\uc194\\ub85c \\uc194\\uc194\\ub791 \\uc194\\uc194\\ub791 \\ub180\\uc544\\n\\n\"\n",
              "    }\n",
              "  ],\n",
              "  \"created\": 1611297897,\n",
              "  \"id\": \"cmpl-2KkThPGkYef5Ila2J27uNnRXAZcho\",\n",
              "  \"model\": \"davinci:2020-05-03\",\n",
              "  \"object\": \"text_completion\"\n",
              "}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BykbV3n55yb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlH3v1RFzyJF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}